# ğŸ¥ HealthPay Claim Document Processor

A FastAPI-based backend pipeline that processes medical claim PDFs using LLMs and agentic workflows.

## ğŸ¥ Demo Video:
Watch the working Demo:[https://www.loom.com/share/65b13027910541cfaddff39872a21405?sid=43f44f56-2d95-4398-8f17-fa53a050b544]

## ğŸ”§ Architecture

- **FastAPI**: Main API server
- **Agent Modules**:
  - `ClassifierAgent`: Classifies PDFs as bill, discharge_summary, or ID
  - `BillAgent`: Extracts bill-related fields via LLM
  - `DischargeAgent`: Extracts discharge summary details
  - `ValidationAgent`: Validates structure and checks for missing/inconsistent data
- **PDF Parser**: PyMuPDF used to extract text from uploads
- **LLM**: OpenRouter + GPT 3.5 Turbo (or Gemini)

## ğŸ” Flow

1. Upload multiple PDFs to `/process-claim`
2. Each is classified using LLM
3. Text is routed to bill/discharge agents
4. Extracted JSON is validated
5. Final claim decision is returned

## ğŸ¤– AI Tools Used

- **OpenRouter**: for LLM access
- **ChatGPT**: for agent prompting & architecture design
- **Cursor**: for fast in-editor prompting and test generation

### Prompt Examples:

#### Classifier Agent

Classify the following text as one of: bill, discharge_summary, id_card. Return only the label.

### Bill Agent

--Extract the following from the hospital bill: hospital_name, total_amount, date_of_service. Return as JSON.

### Discharge Agent

--Extract patient_name, diagnosis, admission_date, discharge_date. Return as a JSON object.

ğŸ§ª Testing
Upload sample PDFs via Swagger (/docs)

See JSON output with validation and claim status

ğŸ“ Project Structure

healthpay-backend/
â”‚
â”œâ”€â”€ app/                       # Main application code
â”‚   â”œâ”€â”€ main.py                # FastAPI app instance
â”‚   â”œâ”€â”€ api.py                 # Route for /process-claim
â”‚   â”‚
â”‚   â”œâ”€â”€ agents/                # LLM-powered agents
â”‚   â”‚   â”œâ”€â”€ base_agent.py
â”‚   â”‚   â”œâ”€â”€ classifier_agent.py
â”‚   â”‚   â”œâ”€â”€ bill_agent.py
â”‚   â”‚   â”œâ”€â”€ discharge_agent.py
â”‚   â”‚   â””â”€â”€ validation_agent.py
â”‚   â”‚
â”‚   â”œâ”€â”€ services/              # Supporting services
â”‚   â”‚   â”œâ”€â”€ pdf_service.py     # PDF text extraction
â”‚   â”‚   â””â”€â”€ llm_service.py     # OpenRouter API wrapper
â”‚   â”‚
â”‚   â”œâ”€â”€ models/                # (Optional) Pydantic models
â”‚   â”‚   â””â”€â”€ schema.py
â”‚
â”œâ”€â”€ tests/                     # Test cases
â”‚   â””â”€â”€ test_processor.py
â”‚
â”œâ”€â”€ .env.example               # Sample environment file (no secrets)
â”œâ”€â”€ requirements.txt           # Python dependencies
â”œâ”€â”€ Dockerfile                 # Docker container configuration
â”œâ”€â”€ README.md                  # Project documentation
â””â”€â”€ .dockerignore              # Files to exclude from Docker image



## ğŸ³ Docker Setup (Run Locally)

You can build and run this FastAPI app using Docker:

### 1. Clone the Repository

```bash
1.git clone https://github.com/shivamkumarrai1/healthpay-backend.git
cd healthpay-backend

2. Build the Docker Image
docker build -t healthpay-app.

3. Run the Container
docker run -p 8000:8000 healthpay-app
Then open in your browser: 
http://localhost:8000/docs
(Or http://192.168.99.100:8000/docs if using Docker Toolbox)

ğŸ“ .env Configuration
Create a .env file or copy from .env.example with your LLM key:

OPENROUTER_API_KEY=your_api_key_here
OPENROUTER_MODEL=openai/gpt-3.5-turbo
